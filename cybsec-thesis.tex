\documentclass[a4paper, 12pt]{article} 
\usepackage[top=2.5cm, bottom=2.5cm, left=3cm, right=3cm, includefoot]{geometry} % Geometry of the page

\usepackage{graphicx} % Figures inside text
\usepackage{titlesec} % For editing titles
\usepackage{longtable} % For creating page wide tables
\usepackage{multirow} % Needed for merging multiple rows in a table 
\usepackage{todonotes} % For adding todo notes in the work
\usepackage{url} % For using URLs
\usepackage{float} % For formating tables and figures
\usepackage{blindtext} % Stubs
\usepackage{pgfplots} % For plotting
\usepackage[T2A,T1]{fontenc} % For using estonian and russian letters
\usepackage[utf8]{inputenc} % %UTF8 decoding
\usepackage{tocloft} % For editing contents
\usepackage{amssymb} % For square itemized lists
\renewcommand{\labelitemi}{\tiny$\blacksquare$} %For square itemized lists
\usepackage{caption} % Used when captioning tables and figures
\captionsetup{labelsep=period} % Adds period to the end of table or figure
\usepackage{verbatimbox} %To put program code in the center using Verbatim
\titlelabel{\thetitle.\quad} % Adds period at the end of titles
\usepackage{times} % Times type text
\usepackage{fancyhdr} % Usage of headers and footers 
\setlength{\parindent}{0cm} % Paragraph intent is set to 0
\usepackage{setspace} % Used for spacing of text
\onehalfspacing % 1,5 spacing between lines of text
\setlength{\parskip}{\baselineskip}
\setcounter{secnumdepth}{4} % Levels
\usepackage{hyperref} % clickable references
\usepackage[]{algorithm2e} % pseudocode
\usepackage{tikz} % for drawing graphs
\usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}
\usepackage{amsmath} % Math symbols
\usepackage{lastpage} % last page
\usepackage{listings} % syntax highlight
\usepackage{enumitem}
\usepackage{subfig}
\usepackage{lscape}
\usepackage{tabularx}

% redefine section so that it would start every time on a new page
\let\stdsection\section
\renewcommand\section{\newpage\stdsection}

% syntax highlight for vhdl
\definecolor{black}{rgb}{0,0,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\lstset{frame=tb,
	language=vhdl,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{gray},
	commentstyle=\color{dkgreen},
	stringstyle=\color{gray},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}


\begin{document}

%------------------------------TITLE PAGE---------------------------------
\thispagestyle{fancy} 
\renewcommand{\headrulewidth}{0pt} 
\renewcommand{\footrulewidth}{0pt} 
\headheight = 57pt 
\headsep = 0pt 

\chead{ 
 \textsc{\begin{Large}
	Tallinn University of Technology\\
	\end{Large} }
	Faculty of Information Technology\\
	Department of Cyber Security
}
\vspace*{7 cm}

\begin{center} 
IVCM09/14\\[0cm]
Urmo Lihten 143912IVCM\\
\begin{LARGE}
	\textsc{Detection of Process Abuse and Data Request Misuse on Electronic Health Record System Based on Request Logs 	\\}
%\textsc{Implementing neuroevolution on reprogrammable hardware\\}
\end{LARGE}
Master Thesis\\[2cm]
\end{center}

\begin{flushright} %Joondab teksti paremale
Supervisor: Firstname Lastname PhD\\

Co-Supervisor: Firstname Lastname MSc\\[0cm]

\end{flushright}

\cfoot{Tallinn 2020}
%\renewcommand{\headrulewidth}{0pt} %Eemaldab päisest horisontaalse joone
\pagebreak %Lehe lõpp

%------------------------------TIITELLEHT EST---------------------------------
\thispagestyle{fancy} %Leht sisaldab päist ja jalust
\renewcommand{\headrulewidth}{0pt} %Eemaldab päisest horisontaalse joone
\renewcommand{\footrulewidth}{0pt} %Eemaldab jalusest horisontaalse joone
\headheight = 57pt %Paneb paika päise laiuse (vastavalt kompilaatori soovitusele)
\headsep = 0pt %Vähendab päise ja teksti vahelise kauguse nullini
%\footskip = 10pt %Jaluse ruum

\chead{ %Paigutab järgneva teksti päises keskele
	\textsc{\begin{Large} %Tekst suurtähtedega ja suuremaks
			Tallinna tehnikaülikool\\
		\end{Large} }
		Infotehnoloogia teaduskond\\
		Arvutitehnika instituut
	}

	\vspace*{7 cm} %Tekitab lehe alguse ja teksti vahele tühja ala vastava laiusega

	\begin{center} %Tekst keskele
		IAY70LT\\[0cm]
		Firstname Lastname 123456 ABCD\\
		\begin{LARGE}
			\textsc{Protsessi kõrvalekallete ja andmepäringute väärkasutuse avastamine Tervise Infosüsteemis päringu logide põhjal\\}
			%\textsc{Implementing neuroevolution on reprogrammable hardware\\}
		\end{LARGE}
		Magistritöö\\[2cm]
	\end{center}

	\begin{flushright} %Joondab teksti paremale
		Juhendaja: Firstname Lastname PhD\\

		Kaasjuhendaja: Firstname Lastname MSc\\[0cm]

	\end{flushright}

	\cfoot{Tallinn <year>} %Lisab asukoha ja kuupäeva jalusesse
	%\renewcommand{\headrulewidth}{0pt} %Eemaldab päisest horisontaalse joone
	\pagebreak %Lehe lõpp


%---------------------------Author's declaration of originality-------------------------
\section*{\begin{center} Author's declaration of originality \end{center}}
I hereby certify that I am the sole author of this thesis and that no part of this thesis has been published or submitted for publication.
All works and major viewpoints of the other authors, data from other sources of literature and elsewhere used for writing this paper have been referenced.

%Autorideklaratsioon on iga lõputöö kohustuslik osa, mis järgneb tiitellehele.
%Autorideklaratsioon esitatakse järgmise tekstina:
%
%Olen koostanud antud töö iseseisvalt. Kõik töö koostamisel kasutatud teiste autorite tööd, olulised seisukohad, kirjandusallikatest ja mujalt pärinevad andmed on viidatud. Käsolevat tööd ei ole varem esitatud kaitsmisele kusagil mujal.

Author: Urmo Lihten

\today
\pagebreak

%-----------------------------ABSTRACT-----------------------------------
\section*{\begin{center}
Abstract
\end{center}}
Here goes your abstract...

The thesis is in English and contains \pageref{LastPage} pages of text, 5 chapters, 23 figures, 8 tables.
\pagebreak
%---------------------------ANNOTATSIOON---------------------------------
\section*{\begin{center}
Annotatsioon
\end{center}}

Annotatsioon on lõputöö kohustuslik osa, mis annab lugejale ülevaate töö eesmärkidest, olulisematest käsitletud probleemidest ning tähtsamatest tulemustest ja järeldustest. Annotatsioon on töö lühitutvustus, mis ei selgita ega põhjenda midagi, küll aga kajastab piisavalt töö sisu. Inglisekeelset annotatsiooni nimetatakse Abstract, venekeelset aga

Sõltuvalt töö põhikeelest, esitatakse töös järgmised annotatsioonid:
\begin{itemize}
\item kui töö põhikeel on eesti keel, siis esitatakse annotatsioon eesti keeles mahuga $\frac{1}{2	}$ A4 lehekülge ja annotatsioon \textit{Abstract} inglise keeles mahuga vähemalt 1 A4 lehekülg;
\item kui töö põhikeel on inglise keel, siis esitatakse annotatsioon (Abstract)  inglise keeles mahuga $\frac{1}{2}$ A4 lehekülge ja annotatsioon eesti keeles mahuga vähemalt 1 A4 lehekülg;
\end{itemize}

Annotatsiooni viimane lõik on kohustuslik ja omab järgmist sõnastust:

Lõputöö on kirjutatud inglise keeles ning sisaldab teksti \pageref{LastPage} leheküljel, 5 peatükki, 23 joonist, 8 tabelit.
\pagebreak
%---------------------LÜHENDITE JA MÕISTETE SÕNASTIK---------------------
\section*{Glossary of Terms and Abbreviations}

\begin{tabular}{p{3cm}p{11cm}}
ATI&TTÜ Arvutitehnika instituut\\
DPI&\textit{Dots per inch}, punkti tolli kohta

\end{tabular}
\pagebreak
%----------------------------Contents----------------------------------
\tableofcontents
\newpage
%----------------------List of figures-------------------------------
\listoffigures
\pagebreak
%----------------------List of tables---------------------------------
\listoftables
\pagebreak
%-----------------------------SISSEJUHATUS-------------------------------
\section{Introduction}
\label{Introduction} %Allows referencing titles with \ref 
Estonian Health Information System gives doctors the ability to send patient data to centralized information system. From there other medical workers and also the patient can view entered documents and information. This also gives doctors and nurses access to private data, when they are doing examinations and other procedures to their patients. 

\subsection{Problem statement}
Since medical staff can view peoples medical historyin Health Information System, this poses security threat of misusing the queried data. All that is needed, to see the information, is the persons identification code. 

It is hard to determine, if patient has really turned to them for medical help or not. 
When in an emergency and patient is un-cooperative or in such state unable to communicate, patients identity has to be confirmed without an persons consent.
Permission or rights to view patients data is usully given, when the person turns to the doctor with medical issue. 
Meaning, the permission is not spefically given in the information system and thus allowing view data knowing just the persons personal 
This allows medical staff to open any persons medical history and view it at any given time whether the person has any medical relationship to that medical staff or does not. 

When a persons private data such as medical information is viewed and used, then there has to be a reason. Even if it wrongly done but is still explainable (wrong identification code submission into the system by accident due to similarities, typing wrongly by mistake or third person has given wrong patient identification code by accident). 

To solve this problem is to detect health records data misusage and errors in the process as early as possible by analyzing Health Information System logs what include data requests and documents sent. Learning about the different processes in which different queries has to be made within patient treatment and data forwarded. This gives the possibility to detect processes and its anomalies - queries and documents sent when not needed or out of the ordinary. Upon problem detection healthcare service provider can be contacted and be questioned, if action was intententional or not. Also to find out the reason. If the misuse is very serious, proper action has to be taken by proper authorities. 

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=3cm]{img/example.png} % edit the width according to need
%	\caption{Tallinn University of Technology \cite{urlSource}}
%	\label{fig:ttuExample}
%\end{figure}

%Example of referencing to figure \ref{fig:ttuExample}. Example of citing something \cite{urlSource}.

%-------------------------------TOPIC START---------------------------
\section{Approach overview}
Estonian Health Information System logs every data query and document sent to it as requests. Every response is either data from queried documents and/or from subqueries to other data providers or approvement, that document or data is saved. 
Before the request reaches to the database, there are multiple layers of services that receive the request and examine it, if the organization is allowed to send it, if its properly constructed to its standard, if the syntax of query is valid and if subqueries to other information systems is needed. When some part of the checks and validations fail to accept the query, proper error message is sent as an response. If data query is too large or query requests data for large period then information system might cancel the query if it takes a long time to respond or its unable to respond. 
Requests and responses are sent as XML SOAP messages. These contain different object identification codes to classify each document and query. 

Usually every request is made following a certain process. This is agreed upon on an organizational and national level. In information system the process model might be different and needs to be found out. For this process mining tools and machine learning techniques could help to create process models and check conformance. Also detect anomalies is data usage. 

Every request has to be parsed for certain data fields, which give input for the process mining tools to form a process model. After that, a conformance check can be made to find anomalies and machine learning helps to find out data misusages. 

\subsection{Data cleansing}
Logs have large amount data and not every piece of it is needed. These have to be cleansed and selected what to use with machine learning algorithms. If data is doubled (same thing but different representation) then the doubled data does not give anything new value to analyze and learn. Other data, that does not help the inital goal, also is not valueable. 

Goal is to detect abuse and misuse of data requests. These requests have standardized fields of objects and their values according to X-Road request and response structure and international electronic health record HL7 standard. 

To avoid any friction of the data protection law and persons private data, selection of data fields is chosen. This is conformed with Health and Welfare Informations Systems Centre information security specialists and ethics commitee in Ministry of Social Affairs. 

Selected data include health care organizations national registry code, healthcare organization workers identification code (who made the request), request type, response type, request timestamp, response timestamp, document type, sent document number (anonymized), responsed document number(s) (anonyimized), document forwarded timestamp, patients identification code (anonymized). 

Organizations and persons Identification and document numbers are needed to maintain relationships between differents requests and chain together requests and documents queried or sent and form a process model based on the data. This helps to find differences in process models used by organizations and give insight what could be better or data is being used. 

Anonymized data is generated to hide any visiable and person identifiable information from the logs since we do not need to find out specific persons data - we have to maintain the requests and responses relationships to a process model done for specific person or their medical case what needs to be conformed and any misuse should be identifiable. 

Data cleansing is done by pulling logs and parsing them through and extracting required data fields to a table format 

\subsection{Data representation}
Gathered data is saved in a table format Python module Pandas dataframe (similar to excel spreadsheet or CSV file). Every row describes a log entry and column represents log entries attributes what have been previously extracted and were limited to in regards of the information protection law and information security requirements. 

\subsection{Methods for parsing logs for needed data}
Logs are collected, viewable and searchable through ELK stack (ElasticSearch, Logstash, Kibana). From x-Road servers each data request and response is sent to a centralized logging system called Logstash. After processing the incoming log streams, data is stored (or stashed) in ElasticSearch for being searchable. Kibana allows to do analytics and graphs based on that previously stored data. 

Data is stored in a JSON format. Unfortunately X-road requests and responsed are in SOAP XML format which means there is XML code in JSON. XML has to be extracted out from a JSON array from a specific position. After extracting, XML has to be parsed to get needed values and place these in a dataset in a table. Keeping in mind, that in the JSON part from ElasticSearch has other metadata fields for the log line and is also needed to form a process model and chains for the happend processes. 

Python scripting is used to connect ElasticSeach API and pull data from an specific index related to X-road security server logs. Each log row is going to be parsed and 'message' column contains the most valueable part of the log row -  the request or the response , what has been sent through. Other parts are also relevant - timestamp, is it a reponse log row or not, what service is being queried and what organization did the query. 

Dataset example from ElasticSearch first query is imaged below and after eliminating unnessesary columns called "tags" and "archived" which are logging system specific values and do not provide additional value to the query logs. Other values are time (when it came in to the logging server), is it a response log row or not, query subsystem code (what service or system made that query), query identification code, timestamp of the query or response, message (payload of the query or response), memberclass (what type of organization made the query - national organisation or government entity), version of the document in the logging server, id of the query in the logging system. hostname (from which security server or cluster it came from, membercode as the organization registration number in Estonia). 

\begin{figure}[h]
	\centering
	\includegraphics[width=15cm]{img/first_dataset_example.png} % edit the width according to need
	\caption{first dataset example from elasticsearch to python pandas dataframe}
	\label{fig:first dataset example}
\end{figure}

Actual query and response part of the log row (the column named "message") is in XML code and some needed values for process modeling can be get only from there. This also provides some diffeculties since the queries can contain simple XML parameters and others contain large XML codes in an SOAP XML envelope. Meaning parsing through different types of queries of different services might require multiple XML code parsing loops before needed value can be found and extracted for process mining to have basis to work on. 

 Event names in the Estonian Health Information System (leaving out the external services that are being used to create some of the health record documents) are described with XML template ID codes which corresponds to the HL7 standardized documents. Descriptions to these are published by Health and Welface Information Systems Centre's publication center webservice located at http://pub.e-tervis.ee . 

Following is a dataset example to which log parsing and needed value extraction has to reach, to put togeter an event log for process mining procedure. 

\begin{landscape}

\begin{table}[]
	\centering
	\small
	\begin{tabular}{lllllllll}
		\hline
		timestamp &
		response &
		member &
		identification &
		subsystem &
		document/query type &
		query id &
		document id sent &
		document id(s) received in response \\ \hline
		2020-03-16T00:00:01.092Z & False & 70009770 & EE11111111111 & digilugu & 1.3.6.1.4.1.28284.6.1.1.172 & b551911b-6e5a & -              & -              \\
		2020-03-16T00:00:02:092Z &
		True &
		70009770 &
		EE11111111111 &
		digilugu &
		1.3.6.1.4.1.28284.6.1.1.173 &
		b551911b-6e5a &
		- &
		20200316000000,20200315232000 \\
		2020-03-16T00:00:05.092Z & False & 70007446 & EE11111111112 & hksos    & 1.3.6.1.4.1.28284.6.1.1.169 & 17fad00b-13b0 & 20200315235921 &                \\
		2020-03-16T00:00:07.324Z & True  & 70009770 & EE11111111112 & digilugu & 1.3.6.1.4.1.28284.6.1.1.49  & 17fad00b-13b0 & -               & 20200315235921 \\ \hline
	\end{tabular}

	\caption{TO BE dataset example}
	\label{tab:dataset example}
\end{table}
\end{landscape}


\section{Discovering process models}

\subsection{Clustering request types}


%-------------------------------CONCLUSION---------------------------
\section{Conclusion}
\label{Conclusion} 
\pagebreak

%-------------------------------Bibliography-------------------------
\bibliographystyle{ieeetr}
\footnotesize
\setstretch{0}
\bibliography{literature}  % viide bibtex failile (literature.bib)
\end{document}
